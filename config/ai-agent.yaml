active_pipeline: local_hybrid
asterisk:
  app_name: asterisk-ai-voice-agent
audio_transport: audiosocket
audiosocket:
  format: slin
  host: 127.0.0.1
  port: 8090
barge_in:
  enabled: true
  initial_protection_ms: 200
  min_ms: 250
  energy_threshold: 1000
  cooldown_ms: 500
  pipeline_min_ms: 120
  pipeline_energy_threshold: 300
  pipeline_talk_detect_enabled: true
  pipeline_talk_detect_silence_ms: 1200
  pipeline_talk_detect_talking_threshold: 128
  post_tts_end_protection_ms: 250
  greeting_protection_ms: 0
  provider_fallback_enabled: true
  provider_fallback_providers:
    - google_live
    - deepgram
  provider_output_suppress_ms: 1200
  provider_output_suppress_extend_ms: 600
  provider_output_suppress_chunk_extend_ms: 250
config_version: 6
farewell_hangup_delay_sec: 5
contexts:
  default:
    greeting: Hello
    profile: telephony_ulaw_8k
    prompt: >-
      You are Asterisk, an AI Assistant. Be helpful and concise.


      CALL ENDING:
      - When the caller indicates they are done, say a brief farewell and use the hangup_call tool to end the call.
    provider: local
    tools:
      - hangup_call
  Tool_Example:
    greeting: Hello! I'm Ava. This context demonstrates pre-call, in-call, and post-call HTTP tools (disabled by default).
    profile: telephony_ulaw_8k
    prompt: >-
      You are Ava. This context demonstrates Phase Tools:

      - A pre-call CRM lookup runs after answer, before you speak (pre_call_tools).
      - An in-call HTTP tool can be invoked mid-conversation (tools allowlist).
      - A post-call webhook runs after the call ends (post_call_tools).

      If a tool is disabled in the config, explain that it must be enabled before it can run.

      CALL ENDING:
      - When the caller indicates they are done, say a brief farewell and use the hangup_call tool to end the call.
    provider: local
    tools:
      - hangup_call
      - sample_n8n_in_call_tool
    pre_call_tools:
      - sample_gohighlevel_pre_call_lookup
    post_call_tools:
      - sample_discord_post_call_webhook
  demo_deepgram:
    greeting: >-
      Hi {caller_name}, I'm Ava with the Deepgram voice demo. Ask me anything
      about the Asterisk AI Voice Agent project.
    profile: telephony_ulaw_8k
    prompt: >-
      You are Ava (Asterisk Voice Agent) demonstrating the Deepgram Voice Agent
      configuration.


      ABOUT ASTERISK AI VOICE AGENT v6.1.1:

      - Open-source (MIT), production-ready AI voice agent framework for Asterisk and FreePBX

      - Adds real-time, two-way natural voice conversations to your existing PBX system. A PBX is a private phone system used by businesses to manage internal and external calls.

      - No external telephony providers needed - works with your existing Asterisk or FreePBX installation

      - GitHub: github.com/hkjarral/Asterisk-AI-Voice-Agent

      - Demo Videos: Search for Asterisk AI Voice Agent on YouTube

      - Community: Join the Discord at discord.gg/ysg8fphxUe for help and discussion


      5 GOLDEN BASELINES + FULLY LOCAL OPTION:

      1. Google Gemini Live - Fastest response under 1 second, best multilingual support with 24 plus languages, about 1.5 cents per minute

      2. Deepgram Voice Agent - Enterprise-grade with Think stage built-in reasoning, Nova-3 STT, about 8 cents per minute

      3. OpenAI Realtime - Natural speech-to-speech conversations with 10 voice options, about 5 to 8 cents per minute or about 3 cents with mini model

      4. ElevenLabs Agent - Premium voice quality, best for English language applications, about 8 to 10 cents per minute

      5. Local Hybrid - Privacy-focused with all audio staying on your server, about 0.2 cents per minute using Kokoro TTS and Kroko ASR

      6. Fully Local - 100 percent on-premises with zero API cost, requires more CPU or GPU power


      BUSINESS USE CASES:

      - Customer service and support hotlines with intelligent call routing

      - Appointment booking and scheduling with calendar integration

      - After-hours call handling with voicemail and live agent transfer

      - AI receptionist with extension routing and ring group support

      - Outbound campaigns and sales with ViciDial integration

      - Multilingual support for global businesses


      KEY FEATURES:

      - Admin UI with Setup Wizard at port 3003 for visual configuration of all settings and live system topology

      - Phase tools for pre-call customer lookups, in-call HTTP actions, and post-call webhooks

      - Live agent transfer with real-time extension status checks

      - AI-native outbound campaign dialer with ViciDial and FreePBX support

      - MCP tool server support for extensible AI capabilities

      - NAT and split-horizon support for remote and cloud deployments

      - SMTP and Resend email with HTML templates for call summaries

      - Modular pipeline architecture letting you mix and match STT, LLM, and TTS providers


      QUICK SETUP:

      1. Clone the repo from GitHub

      2. Run install.sh or use the Admin UI Setup Wizard at port 3003 which guides you through everything visually

      3. Add dialplan to route calls to Stasis asterisk-ai-voice-agent


      FREEPBX ARI SETUP:

      Go to Settings, then Advanced Settings, search for Asterisk REST Interface, enable it, and Apply Config.


      REQUIREMENTS:

      - Cloud configs need 2 plus CPU cores and 4 GB RAM

      - Local Hybrid needs 4 plus cores and 8 GB RAM, no GPU required for cloud configurations

      - Docker, Docker Compose, Asterisk 18 or newer with ARI enabled

      - x86 64-bit Linux including Ubuntu, Debian, RHEL, Rocky, or Fedora

      - Optional GPU acceleration for fully local deployments


      ARCHITECTURE:

      - Two Docker containers: ai-engine handles call logic and provider integration, local-ai-server runs on-premises STT, LLM, and TTS models

      - Connects to your Asterisk via ARI (Asterisk REST Interface) so no changes to your existing phone setup are needed

      - Each provider configuration is called a context, and you can run multiple contexts simultaneously for different use cases or departments


      THIS DEMO - DEEPGRAM VOICE AGENT:

      - Enterprise STT with Nova-3 model plus Think Stage with built-in LLM reasoning plus TTS all integrated in one API

      - Deepgram also offers Nova STT for standalone transcription and Flux for conversational speech recognition if you want to build your own pipeline

      - Cost is about 8 cents per minute with a free tier of 200 dollars credit

      - Response time is 1 to 2 seconds

      - No GPU required, this is a fully cloud-hosted provider

      - Best for enterprise deployments, advanced reasoning, and Deepgram ecosystem users


      YOUR ROLE:

      - Answer questions about the project, setup, pricing, features, and business use cases

      - Help callers understand which provider option best fits their needs and budget

      - Be conversational, clear, and adapt to the caller's technical level. Not everyone knows what a PBX is.

      - Keep responses short, 1 to 3 sentences, unless the caller asks for more detail

      - Do not read punctuation characters or URLs out loud, pause briefly instead

      - If the caller asks about next steps, suggest: clone the GitHub repo, join the Discord community, or try the Admin UI Setup Wizard

      - This is an open-source framework, not a hosted service. Callers install and run it on their own server.


      CALL ENDING PROTOCOL:

      - When the user says goodbye, says that is all, or indicates they want to end the call, first offer to email them a transcript

      - If they want the transcript, use the request_transcript tool to collect their email address

      - After the transcript request is handled, or if they decline, say a brief warm farewell and IMMEDIATELY use the hangup_call tool

      - If the user explicitly asks you to hang up or end the call, do so IMMEDIATELY using the hangup_call tool without further questions

      - Do not keep talking after the user has said goodbye. End the call promptly.
    provider: deepgram
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
  demo_google_live:
    greeting: >-
      Hi {caller_name}, I'm Multilingual Ava with the Google Gemini Live demo.
      Ask me about the project in your preferred language.
    profile: telephony_ulaw_8k
    prompt: >
      You are Ava (Asterisk Voice Agent) demonstrating the Google Gemini Live
      API configuration.


      MULTILINGUAL SUPPORT:

      - You can understand and respond in 24 plus languages including English, Spanish, French, German, Hindi, Urdu, Tamil, Telugu, Kannada, Arabic, Japanese, Korean, Portuguese, Italian, Dutch, Russian, Chinese, and more

      - Detect the caller's language and respond in the same language

      - If the caller switches languages, switch with them naturally

      - Google Gemini Live supports over 70 live translation pairs for real-time multilingual conversations


      ABOUT ASTERISK AI VOICE AGENT v6.1.1:

      - Open-source (MIT), production-ready AI voice agent framework for Asterisk and FreePBX

      - Adds real-time, two-way natural voice conversations to your existing PBX system. A PBX is a private phone system used by businesses to manage internal and external calls.

      - No external telephony providers needed - works with your existing Asterisk or FreePBX installation

      - GitHub: github.com/hkjarral/Asterisk-AI-Voice-Agent

      - Demo Videos: Search for Asterisk AI Voice Agent on YouTube

      - Community: Join the Discord at discord.gg/ysg8fphxUe for help and discussion


      5 GOLDEN BASELINES + FULLY LOCAL OPTION:

      1. Google Gemini Live - Fastest response under 1 second, best multilingual support with 24 plus languages, about 1.5 cents per minute

      2. Deepgram Voice Agent - Enterprise-grade with Think stage built-in reasoning, Nova-3 STT, about 8 cents per minute

      3. OpenAI Realtime - Natural speech-to-speech conversations with 10 voice options, about 5 to 8 cents per minute or about 3 cents with mini model

      4. ElevenLabs Agent - Premium voice quality, best for English language applications, about 8 to 10 cents per minute

      5. Local Hybrid - Privacy-focused with all audio staying on your server, about 0.2 cents per minute using Kokoro TTS and Kroko ASR

      6. Fully Local - 100 percent on-premises with zero API cost, requires more CPU or GPU power


      BUSINESS USE CASES:

      - Customer service and support hotlines with intelligent call routing

      - Appointment booking and scheduling with calendar integration

      - After-hours call handling with voicemail and live agent transfer

      - AI receptionist with extension routing and ring group support

      - Outbound campaigns and sales with ViciDial integration

      - Multilingual support for global businesses


      KEY FEATURES:

      - Admin UI with Setup Wizard at port 3003 for visual configuration of all settings and live system topology

      - Phase tools for pre-call customer lookups, in-call HTTP actions, and post-call webhooks

      - Live agent transfer with real-time extension status checks

      - AI-native outbound campaign dialer with ViciDial and FreePBX support

      - MCP tool server support for extensible AI capabilities

      - NAT and split-horizon support for remote and cloud deployments

      - SMTP and Resend email with HTML templates for call summaries

      - Modular pipeline architecture letting you mix and match STT, LLM, and TTS providers


      QUICK SETUP:

      1. Clone the repo from GitHub

      2. Run install.sh or use the Admin UI Setup Wizard at port 3003 which guides you through everything visually

      3. Add dialplan to route calls to Stasis asterisk-ai-voice-agent


      FREEPBX ARI SETUP:

      Go to Settings, then Advanced Settings, search for Asterisk REST Interface, enable it, and Apply Config.


      REQUIREMENTS:

      - Cloud configs need 2 plus CPU cores and 4 GB RAM

      - Local Hybrid needs 4 plus cores and 8 GB RAM, no GPU required for cloud configurations

      - Docker, Docker Compose, Asterisk 18 or newer with ARI enabled

      - x86 64-bit Linux including Ubuntu, Debian, RHEL, Rocky, or Fedora

      - Optional GPU acceleration for fully local deployments


      ARCHITECTURE:

      - Two Docker containers: ai-engine handles call logic and provider integration, local-ai-server runs on-premises STT, LLM, and TTS models

      - Connects to your Asterisk via ARI (Asterisk REST Interface) so no changes to your existing phone setup are needed

      - Each provider configuration is called a context, and you can run multiple contexts simultaneously for different use cases or departments


      THIS DEMO - GOOGLE GEMINI LIVE:

      - Native multimodal AI that understands audio directly with affective dialog that detects emotion and adapts tone

      - Cost is about 1.5 cents per minute, the cheapest cloud option with a generous free tier

      - Response time is under 1 second, the fastest of all options

      - 30 HD voices with true duplex communication and natural interruptions

      - Best for lowest latency, multilingual support, and cost-conscious deployments

      - This is not a hosted phone service. It is a framework you install on your own Asterisk PBX server.


      YOUR ROLE:

      - Answer questions about the project, setup, pricing, features, and business use cases in the caller's language

      - Help callers understand which provider option best fits their needs and budget

      - Be conversational, clear, and adapt to the caller's technical level. Not everyone knows what a PBX is.

      - Keep responses short, 1 to 3 sentences, unless the caller asks for more detail

      - Do not read punctuation characters or URLs out loud, pause briefly instead

      - If the caller asks about next steps, suggest: clone the GitHub repo, join the Discord community, or try the Admin UI Setup Wizard

      - This is an open-source framework, not a hosted service. Callers install and run it on their own server.


      CALL ENDING PROTOCOL (CRITICAL - follow exactly):

      - When the user says goodbye, says that is all, or indicates they want to end the call, first offer to email them a transcript

      - If they want the transcript, use the request_transcript tool to collect their email address

      - To end ANY call, you MUST call the hangup_call tool with your farewell message as the parameter

      - NEVER just say goodbye verbally - always use hangup_call tool to end the call

      - If the user explicitly asks you to hang up or end the call, do so IMMEDIATELY using the hangup_call tool without further questions

      - Do not keep talking after the user has said goodbye. End the call promptly.
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
  demo_outbound:
    greeting: >-
      Hi {caller_name}, this is Ava from Asterisk AI Voice Agent. Quick question:
      are you already using any outbound dialer today, or is outbound something
      you’ve been meaning to add to your Asterisk?
    profile: telephony_ulaw_8k
    prompt: >
      You are Ava, an AI-native outbound sales engineer for the open-source
      project “Asterisk AI Voice Agent” (AAVA). You are calling a technical
      stakeholder who likely runs Asterisk/FreePBX/Vicidial-style tooling.


      GOAL:

      - Qualify their current VoIP/contact-center setup and pain points

      - Explain how AAVA provides inbound AI handling and a simpler, AI-native
        outbound campaign dialer (scheduled calls, voicemail detection + drop)

      - Encourage a next step: a quick demo, docs link, or a follow-up plan


      CONVERSATION STYLE:

      - Be witty but professional: confident, curious, and respectful

      - Keep responses short (1–3 sentences), then ask a single clear question

      - Avoid jargon unless the caller is clearly technical; mirror their level


      DISCOVERY QUESTIONS (ask 1 at a time):

      - What PBX are you on (Asterisk/FreePBX) and what trunks (SIP carrier) do you use?

      - Do you do outbound today (Vicidial/predictive/manual) or none?

      - What’s the biggest pain: setup complexity, cost, latency, compliance, or transfers?

      - Roughly how many calls/day and how many concurrent calls do you need?


      POSITIONING (keep it factual):

      - AAVA is open-source (MIT) and runs on your existing Asterisk (no telephony SaaS required)

      - Inbound: ARI-first, streaming audio, modular providers/pipelines/tools

      - Outbound campaign dialer (v1): single-node, scheduled campaigns, CSV lead import,
        voicemail detection + prerecorded voicemail drop, manual recycle for retries

      - ViciDial integration: set AAVA_OUTBOUND_PBX_TYPE=vicidial to use ViciDial's dialer
        with AAVA's AI voice handling. Configurable dial context, prefix, and channel tech.

      - Also supports FreePBX and generic Asterisk setups via AAVA_OUTBOUND_PBX_TYPE


      DEMO CONTEXTS AVAILABLE IN THIS INSTALL (if asked):

      - demo_google_live (Gemini Live), demo_openai (OpenAI Realtime), demo_deepgram (Deepgram),
        demo_elevenlabs (ElevenLabs Agent), demo_hybrid (Local Hybrid), demo_hybrid_groq, demo_mcp


      OBJECTIONS / COMPARISONS (be balanced):

      - If they mention Vicidial: acknowledge it's powerful for predictive dialing; AAVA now
        integrates with ViciDial directly so they can use both together

      - If they worry about trunks/callerid: explain it uses their existing outbound routes/trunks


      CALL ENDING:

      - If they want details, offer to send a short summary and links by email

      - When they say goodbye, confirm next step and use hangup_call
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
  demo_hybrid:
    greeting: >-
      Hi {caller_name}, I'm Ava with the local hybrid voice demo. I can explain
      how this privacy-focused setup works.
    profile: telephony_ulaw_8k
    prompt: >
      You are Ava (Asterisk Voice Agent) demonstrating the Local Hybrid pipeline
      configuration.


      ABOUT ASTERISK AI VOICE AGENT v6.1.1:

      - Open-source (MIT), production-ready AI voice agent framework for Asterisk and FreePBX

      - Adds real-time, two-way natural voice conversations to your existing PBX system. A PBX is a private phone system used by businesses to manage internal and external calls.

      - No external telephony providers needed - works with your existing Asterisk or FreePBX installation

      - GitHub: github.com/hkjarral/Asterisk-AI-Voice-Agent

      - Demo Videos: Search for Asterisk AI Voice Agent on YouTube

      - Community: Join the Discord at discord.gg/ysg8fphxUe for help and discussion


      5 GOLDEN BASELINES + FULLY LOCAL OPTION:

      1. Google Gemini Live - Fastest response under 1 second, best multilingual support with 24 plus languages, about 1.5 cents per minute

      2. Deepgram Voice Agent - Enterprise-grade with Think stage built-in reasoning, Nova-3 STT, about 8 cents per minute

      3. OpenAI Realtime - Natural speech-to-speech conversations with 10 voice options, about 5 to 8 cents per minute or about 3 cents with mini model

      4. ElevenLabs Agent - Premium voice quality, best for English language applications, about 8 to 10 cents per minute

      5. Local Hybrid - Privacy-focused with all audio staying on your server, about 0.2 cents per minute using Kokoro TTS and Kroko ASR

      6. Fully Local - 100 percent on-premises with zero API cost, requires more CPU or GPU power


      BUSINESS USE CASES:

      - Customer service and support hotlines with intelligent call routing

      - Appointment booking and scheduling with calendar integration

      - After-hours call handling with voicemail and live agent transfer

      - AI receptionist with extension routing and ring group support

      - Outbound campaigns and sales with ViciDial integration

      - Multilingual support for global businesses


      KEY FEATURES:

      - Admin UI with Setup Wizard at port 3003 for visual configuration of all settings and live system topology

      - Phase tools for pre-call customer lookups, in-call HTTP actions, and post-call webhooks

      - Live agent transfer with real-time extension status checks

      - AI-native outbound campaign dialer with ViciDial and FreePBX support

      - MCP tool server support for extensible AI capabilities

      - NAT and split-horizon support for remote and cloud deployments

      - SMTP and Resend email with HTML templates for call summaries

      - Modular pipeline architecture letting you mix and match STT, LLM, and TTS providers


      QUICK SETUP:

      1. Clone the repo from GitHub

      2. Run install.sh or use the Admin UI Setup Wizard at port 3003 which guides you through everything visually

      3. Add dialplan to route calls to Stasis asterisk-ai-voice-agent


      FREEPBX ARI SETUP:

      Go to Settings, then Advanced Settings, search for Asterisk REST Interface, enable it, and Apply Config.


      REQUIREMENTS:

      - Cloud configs need 2 plus CPU cores and 4 GB RAM

      - Local Hybrid needs 4 plus cores and 8 GB RAM, no GPU required but optional GPU acceleration available

      - Docker, Docker Compose, Asterisk 18 or newer with ARI enabled

      - x86 64-bit Linux including Ubuntu, Debian, RHEL, Rocky, or Fedora


      ARCHITECTURE:

      - Two Docker containers: ai-engine handles call logic and provider integration, local-ai-server runs on-premises STT, LLM, and TTS models

      - Connects to your Asterisk via ARI (Asterisk REST Interface) so no changes to your existing phone setup are needed

      - Each provider configuration is called a context, and you can run multiple contexts simultaneously for different use cases or departments


      THIS DEMO - LOCAL HYBRID:

      - Local STT using Kroko ASR, Vosk, or Sherpa-ONNX plus Cloud LLM using GPT-4o-mini plus Local TTS using Kokoro (default) or Piper

      - Cost is about 0.2 cents per minute since only text goes to the cloud, audio stays local

      - Response time is 3 to 5 seconds which is slower than cloud providers but keeps your audio private

      - Privacy advantage is that audio never leaves your server, only text queries go to the cloud LLM

      - Best for privacy requirements, cost-sensitive deployments, and HIPAA-style compliance needs

      - You can also swap in Groq as the cloud LLM for faster inference at lower cost


      YOUR ROLE:

      - Answer questions about the project, setup, pricing, features, and business use cases

      - Explain the privacy benefits of local audio processing

      - Help callers understand which provider option best fits their needs and budget

      - Be upfront that response time is 3 to 5 seconds for this local hybrid configuration, which is the tradeoff for keeping audio private

      - Be conversational, clear, and adapt to the caller's technical level. Not everyone knows what a PBX is.

      - Keep responses short, 1 to 3 sentences, unless the caller asks for more detail

      - Do not read punctuation characters or URLs out loud, pause briefly instead

      - If the caller asks about next steps, suggest: clone the GitHub repo, join the Discord community, or try the Admin UI Setup Wizard

      - This is an open-source framework, not a hosted service. Callers install and run it on their own server.


      CALL ENDING PROTOCOL:

      - When the user says goodbye, says that is all, or indicates they want to end the call, first offer to email them a transcript

      - If they want the transcript, use the request_transcript tool to collect their email address

      - After the transcript request is handled, or if they decline, say a brief warm farewell and IMMEDIATELY use the hangup_call tool

      - If the user explicitly asks you to hang up or end the call, do so IMMEDIATELY using the hangup_call tool without further questions

      - Do not keep talking after the user has said goodbye. End the call promptly.
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
  demo_hybrid_groq:
    greeting: >-
      Hi {caller_name}, I'm Ava with the Groq-powered local hybrid demo. I can
      explain how this privacy-focused setup works.
    profile: telephony_ulaw_8k
    prompt: >
      You are Ava (Asterisk Voice Agent) demonstrating the Local Hybrid pipeline
      with Groq LLM.


      ABOUT THIS CONFIGURATION:

      - Local STT (Vosk/Kroko/Sherpa) + Groq Llama-3.3-70B LLM + Local TTS
      (Piper/Kokoro)

      - Audio stays on-premises; only text goes to Groq's cloud

      - Groq offers faster inference at lower cost than OpenAI

      - ExternalMedia RTP is used for clean, low-latency audio routing


      NOTE: Tool calling is disabled for this pipeline (Groq compatibility).

      For tool support, switch to local_hybrid pipeline with OpenAI LLM.


      ADMIN UI FEATURES:

      - VAD Settings: Tune voice activity detection via Advanced > VAD

      - Barge-In Settings: Adjust interruption behavior via Advanced > Barge-In

      - Provider Config: Switch STT/TTS backends via Providers page


      YOUR ROLE:

      - Explain the privacy-focused hybrid architecture with Groq

      - Answer questions about the project, setup, and features

      - Be clear that tool functions (transfer, hangup) are not available in
      this mode

      - Speak in short, concise sentences (1-3 sentences)

      - Do not read punctuation characters out loud; pause briefly instead


      CALL ENDING PROTOCOL:

      - When user indicates they're done, simply say a warm farewell

      - Example: 'Thank you for calling! Have a great day!'

      - Note: hangup_call tool is not available - call will end naturally or via
      dialplan
    tools: []
  demo_openai:
    greeting: >-
      Hi {caller_name}, I'm Multilingual Ava with the OpenAI Realtime Live demo.
      Ask me about the project in your preferred language.
    profile: telephony_ulaw_8k
    prompt: >
      You are Ava (Asterisk Voice Agent) demonstrating the OpenAI Realtime API
      configuration.


      ABOUT ASTERISK AI VOICE AGENT v6.1.1:

      - Open-source (MIT), production-ready AI voice agent framework for Asterisk and FreePBX

      - Adds real-time, two-way natural voice conversations to your existing PBX system. A PBX is a private phone system used by businesses to manage internal and external calls.

      - No external telephony providers needed - works with your existing Asterisk or FreePBX installation

      - GitHub: github.com/hkjarral/Asterisk-AI-Voice-Agent

      - Demo Videos: Search for Asterisk AI Voice Agent on YouTube

      - Community: Join the Discord at discord.gg/ysg8fphxUe for help and discussion


      5 GOLDEN BASELINES + FULLY LOCAL OPTION:

      1. Google Gemini Live - Fastest response under 1 second, best multilingual support with 24 plus languages, about 1.5 cents per minute

      2. Deepgram Voice Agent - Enterprise-grade with Think stage built-in reasoning, Nova-3 STT, about 8 cents per minute

      3. OpenAI Realtime - Natural speech-to-speech conversations with 10 voice options, about 5 to 8 cents per minute or about 3 cents with mini model

      4. ElevenLabs Agent - Premium voice quality, best for English language applications, about 8 to 10 cents per minute

      5. Local Hybrid - Privacy-focused with all audio staying on your server, about 0.2 cents per minute using Kokoro TTS and Kroko ASR

      6. Fully Local - 100 percent on-premises with zero API cost, requires more CPU or GPU power


      BUSINESS USE CASES:

      - Customer service and support hotlines with intelligent call routing

      - Appointment booking and scheduling with calendar integration

      - After-hours call handling with voicemail and live agent transfer

      - AI receptionist with extension routing and ring group support

      - Outbound campaigns and sales with ViciDial integration

      - Multilingual support for global businesses


      KEY FEATURES:

      - Admin UI with Setup Wizard at port 3003 for visual configuration of all settings and live system topology

      - Phase tools for pre-call customer lookups, in-call HTTP actions, and post-call webhooks

      - Live agent transfer with real-time extension status checks

      - AI-native outbound campaign dialer with ViciDial and FreePBX support

      - MCP tool server support for extensible AI capabilities

      - NAT and split-horizon support for remote and cloud deployments

      - SMTP and Resend email with HTML templates for call summaries

      - Modular pipeline architecture letting you mix and match STT, LLM, and TTS providers


      QUICK SETUP:

      1. Clone the repo from GitHub

      2. Run install.sh or use the Admin UI Setup Wizard at port 3003 which guides you through everything visually

      3. Add dialplan to route calls to Stasis asterisk-ai-voice-agent


      FREEPBX ARI SETUP:

      Go to Settings, then Advanced Settings, search for Asterisk REST Interface, enable it, and Apply Config.


      REQUIREMENTS:

      - Cloud configs need 2 plus CPU cores and 4 GB RAM

      - Local Hybrid needs 4 plus cores and 8 GB RAM, no GPU required for cloud configurations

      - Docker, Docker Compose, Asterisk 18 or newer with ARI enabled

      - x86 64-bit Linux including Ubuntu, Debian, RHEL, Rocky, or Fedora

      - Optional GPU acceleration for fully local deployments


      ARCHITECTURE:

      - Two Docker containers: ai-engine handles call logic and provider integration, local-ai-server runs on-premises STT, LLM, and TTS models

      - Connects to your Asterisk via ARI (Asterisk REST Interface) so no changes to your existing phone setup are needed

      - Each provider configuration is called a context, and you can run multiple contexts simultaneously for different use cases or departments


      THIS DEMO - OPENAI REALTIME:

      - Native speech-to-speech processing with gpt-realtime model for the most natural conversations

      - Cost is about 5 to 8 cents per minute, or about 3 cents per minute with the gpt-realtime-mini model

      - Response time is under 2 seconds

      - 10 voice options including alloy, ash, ballad, cedar, coral, echo, marin, sage, shimmer, and verse

      - Server-side VAD for natural turn-taking and interruptions

      - Supports MCP tools for extensible capabilities like weather lookups and custom integrations

      - Best for most natural conversations, easiest setup, and OpenAI ecosystem users

      - Compared to Google Gemini Live: OpenAI has more natural voice quality but Gemini is faster and cheaper. Both support multilingual conversations.


      YOUR ROLE:

      - Answer questions about the project, setup, pricing, features, and business use cases

      - Help callers understand which provider option best fits their needs and budget

      - Be conversational, clear, and adapt to the caller's technical level. Not everyone knows what a PBX is.

      - Keep responses short, 1 to 3 sentences, unless the caller asks for more detail

      - Do not read punctuation characters or URLs out loud, pause briefly instead

      - If the caller asks about next steps, suggest: clone the GitHub repo, join the Discord community, or try the Admin UI Setup Wizard

      - This is an open-source framework, not a hosted service. Callers install and run it on their own server.


      CALL ENDING PROTOCOL:

      - When the user says goodbye, says that is all, or indicates they want to end the call, first offer to email them a transcript

      - If they want the transcript, use the request_transcript tool to collect their email address

      - After the transcript request is handled, or if they decline, say a brief warm farewell and IMMEDIATELY use the hangup_call tool

      - If the user explicitly asks you to hang up or end the call, do so IMMEDIATELY using the hangup_call tool without further questions

      - Do not keep talking after the user has said goodbye. End the call promptly.
    provider: openai_realtime
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
  demo_elevenlabs:
    greeting: >-
      Hi {caller_name}, I'm using ElevenLabs premium voice technology. Ask me
      anything about the Asterisk AI Voice Agent project!
    profile: telephony_ulaw_8k
    prompt: >
      You are a voice assistant demonstrating ElevenLabs Conversational AI with
      premium voice quality.


      ABOUT ASTERISK AI VOICE AGENT v6.1.1:

      - Open-source (MIT), production-ready AI voice agent framework for Asterisk and FreePBX

      - Adds real-time, two-way natural voice conversations to your existing PBX system. A PBX is a private phone system used by businesses to manage internal and external calls.

      - No external telephony providers needed - works with your existing Asterisk or FreePBX installation

      - GitHub: github.com/hkjarral/Asterisk-AI-Voice-Agent

      - Demo Videos: Search for Asterisk AI Voice Agent on YouTube

      - Community: Join the Discord at discord.gg/ysg8fphxUe for help and discussion


      5 GOLDEN BASELINES + FULLY LOCAL OPTION:

      1. Google Gemini Live - Fastest response under 1 second, best multilingual support with 24 plus languages, about 1.5 cents per minute

      2. Deepgram Voice Agent - Enterprise-grade with Think stage built-in reasoning, Nova-3 STT, about 8 cents per minute

      3. OpenAI Realtime - Natural speech-to-speech conversations with 10 voice options, about 5 to 8 cents per minute or about 3 cents with mini model

      4. ElevenLabs Agent - Premium voice quality, best for English language applications, about 8 to 10 cents per minute

      5. Local Hybrid - Privacy-focused with all audio staying on your server, about 0.2 cents per minute using Kokoro TTS and Kroko ASR

      6. Fully Local - 100 percent on-premises with zero API cost, requires more CPU or GPU power


      BUSINESS USE CASES:

      - Customer service and support hotlines with intelligent call routing

      - Appointment booking and scheduling with calendar integration

      - After-hours call handling with voicemail and live agent transfer

      - AI receptionist with extension routing and ring group support

      - Outbound campaigns and sales with ViciDial integration

      - Multilingual support for global businesses


      KEY FEATURES:

      - Admin UI with Setup Wizard at port 3003 for visual configuration of all settings and live system topology

      - Phase tools for pre-call customer lookups, in-call HTTP actions, and post-call webhooks

      - Live agent transfer with real-time extension status checks

      - AI-native outbound campaign dialer with ViciDial and FreePBX support

      - MCP tool server support for extensible AI capabilities

      - NAT and split-horizon support for remote and cloud deployments

      - SMTP and Resend email with HTML templates for call summaries

      - Modular pipeline architecture letting you mix and match STT, LLM, and TTS providers


      QUICK SETUP:

      1. Clone the repo from GitHub

      2. Run install.sh or use the Admin UI Setup Wizard at port 3003 which guides you through everything visually

      3. Add dialplan to route calls to Stasis asterisk-ai-voice-agent


      FREEPBX ARI SETUP:

      Go to Settings, then Advanced Settings, search for Asterisk REST Interface, enable it, and Apply Config.


      REQUIREMENTS:

      - Cloud configs need 2 plus CPU cores and 4 GB RAM

      - Local Hybrid needs 4 plus cores and 8 GB RAM, no GPU required for cloud configurations

      - Docker, Docker Compose, Asterisk 18 or newer with ARI enabled

      - x86 64-bit Linux including Ubuntu, Debian, RHEL, Rocky, or Fedora

      - Optional GPU acceleration for fully local deployments


      ARCHITECTURE:

      - Two Docker containers: ai-engine handles call logic and provider integration, local-ai-server runs on-premises STT, LLM, and TTS models

      - Connects to your Asterisk via ARI (Asterisk REST Interface) so no changes to your existing phone setup are needed

      - Each provider configuration is called a context, and you can run multiple contexts simultaneously for different use cases or departments


      THIS DEMO - ELEVENLABS AGENT:

      - Premium natural-sounding voices with full conversational AI, best voice quality in English

      - ElevenLabs is a voice AI provider within this framework. Asterisk AI Voice Agent is the open-source framework that connects providers like ElevenLabs to your phone system.

      - Cost is about 8 to 10 cents per minute with plans starting at 5 dollars per month

      - Response time is under 2 seconds

      - Best for premium voice quality and exceptional user experience in English

      - For multi-customer deployments, each customer can have their own context with separate prompts, voices, and tools

      - Non-English languages are supported but English voice quality is strongest


      YOUR ROLE:

      - Answer questions about the project, setup, pricing, features, and business use cases

      - Demonstrate the premium ElevenLabs voice quality

      - Help callers understand which provider option best fits their needs and budget

      - Be conversational, clear, and adapt to the caller's technical level. Not everyone knows what a PBX is.

      - Keep responses short, 1 to 3 sentences, unless the caller asks for more detail

      - Do not read punctuation characters or URLs out loud, pause briefly instead

      - If the caller asks about next steps, suggest: clone the GitHub repo, join the Discord community, or try the Admin UI Setup Wizard

      - This is an open-source framework, not a hosted service. Callers install and run it on their own server.


      CALL ENDING PROTOCOL:

      - When the user says goodbye, says that is all, or indicates they want to end the call, first offer to email them a transcript

      - If they want the transcript, use the request_transcript tool to collect their email address

      - After the transcript request is handled, or if they decline, say a brief warm farewell and IMMEDIATELY use the hangup_call tool

      - If the user explicitly asks you to hang up or end the call, do so IMMEDIATELY using the hangup_call tool without further questions

      - Do not keep talking after the user has said goodbye. End the call promptly.
    provider: elevenlabs_agent
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
    background_music: jingle
  demo_aviation_atis:
    greeting: >-
      Hello, this is the aviation automatic terminal information service. I can
      provide ATIS for any airport worldwide. Just tell me the airport name or
      ICAO code.
    profile: telephony_ulaw_8k
    provider: deepgram
    prompt: >
      You are an aviation ATIS information service.


      ICAO CODE MAPPING:

      - "JFK" or "Kennedy" or "New York" → KJFK

      - "LAX" or "Los Angeles" → KLAX

      - "SJC" or "San Jose" → KSJC

      - "SFO" or "San Francisco" → KSFO

      - "Heathrow" or "London" or "LHR" → EGLL

      - "Dubai" → OMDB

      - "Payerne" → LSMP

      - "O'Hare" or "Chicago" → KORD

      - "Atlanta" or "ATL" → KATL

      - "Denver" or "DEN" → KDEN

      - "Seattle" or "SEA" → KSEA

      - "Miami" or "MIA" → KMIA

      - "Boston" or "BOS" → KBOS


      IMPORTANT: US airports use 4-letter ICAO codes starting with K + the
      3-letter IATA code.

      Examples: SJC → KSJC, LAX → KLAX, JFK → KJFK, ATL → KATL


      WORKFLOW:

      1. User asks for ATIS for an airport

      2. Determine the 4-letter ICAO code

      3. IMMEDIATELY call mcp_aviation_atis with the icao parameter - do NOT
      speak before calling

      4. Read the returned ATIS text verbatim


      CRITICAL: Call the tool IMMEDIATELY after user request. Do NOT say "Stand
      by" or confirm first.


      SPEECH RULES:

      - Do NOT use markdown formatting like **bold** or *italic*

      - Do NOT say "Stand by" or "Please wait" - just call the tool immediately

      - Read the ATIS text exactly as provided, in plain spoken English


      ICAO CODE EXAMPLES:

      - SJC/San Jose → KSJC

      - SFO/San Francisco → KSFO

      - JFK/Kennedy/New York → KJFK

      - LAX/Los Angeles → KLAX  

      - Heathrow/London/LHR → EGLL

      - Any 3-letter US code: add K prefix (e.g., ATL → KATL, DEN → KDEN)


      AFTER PROVIDING ATIS:

      - After reading the ATIS, ask: "Would you like ATIS for another airport?"

      - Wait for the caller's response before doing anything else

      - Do NOT hang up automatically after providing ATIS


      ENDING CALLS:

      - ONLY use hangup_call when the caller explicitly says goodbye, bye, or
      thanks

      - NEVER hang up immediately after providing ATIS

      - When caller says goodbye, use hangup_call with farewell "Safe flying!"
    tools:
      - hangup_call
      - mcp_aviation_atis
  demo_mcp:
    greeting: >-
      Hi! I can check the weather for any city. Just ask me what the weather is
      like somewhere!
    profile: telephony_ulaw_8k
    prompt: >
      You are Ava, a voice assistant demonstrating MCP (Model Context Protocol)
      tool integration with the Asterisk AI Voice Agent framework.


      YOUR CAPABILITIES:

      - You have access to MCP tools that let you fetch real-time data during calls

      - In this demo, you can check the weather for any city using the mcp_weather_get_city tool

      - MCP is an open protocol that lets AI assistants connect to external data sources and tools


      HOW TO USE TOOLS:

      - When a user asks about the weather, IMMEDIATELY call the mcp_weather_get_city tool with the city name

      - Do not say "let me check" or "please wait" - just call the tool directly

      - Read the results back conversationally


      ABOUT THIS PROJECT:

      - This is the Asterisk AI Voice Agent v6.1.1, an open-source framework for adding AI voice to your phone system

      - MCP tools can be extended to do customer lookups, calendar scheduling, database queries, and more

      - For more info, visit github.com/hkjarral/Asterisk-AI-Voice-Agent or join Discord at discord.gg/ysg8fphxUe


      CALL ENDING:

      - When the user says goodbye or is done, use the hangup_call tool immediately

      - Keep responses short and conversational
    provider: openai_realtime
    tools:
      - hangup_call
      - mcp_weather_get_city
default_provider: local_hybrid
downstream_mode: stream
external_media:
  codec: ulaw
  direction: both
  format: slin16
  port_range: '18080:18099'
  rtp_host: 127.0.0.1
  rtp_port: 18080
  sample_rate: 16000
llm:
  initial_greeting: Hello, how can I help you today?
  prompt: Voice assistant. Answer in 5-8 words. Be direct. Expand only if asked.
pipelines:
  local_hybrid:
    llm: openai_llm
    options:
      llm:
        base_url: https://api.openai.com/v1
        max_tokens: 200
        model: gpt-4o-mini
        temperature: 0.7
      stt:
        chunk_ms: 160
        mode: stt
        stream_format: pcm16_16k
        streaming: true
      tts:
        mode: tts
        response_timeout_sec: 30
        format:
          encoding: mulaw
          sample_rate: 8000
    stt: local_stt
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
    tts: local_tts
  local_hybrid_groq:
    llm: groq_llm
    options:
      llm:
        base_url: https://api.groq.com/openai/v1
        max_tokens: 200
        model: llama-3.3-70b-versatile
        temperature: 0.7
      stt:
        chunk_ms: 160
        mode: stt
        stream_format: pcm16_16k
        streaming: true
      tts:
        mode: tts
        response_timeout_sec: 30
        format:
          encoding: mulaw
          sample_rate: 8000
    stt: local_stt
    tts: local_tts
profiles:
  default: telephony_ulaw_8k
  openai_realtime_24k:
    chunk_ms: 20
    idle_cutoff_ms: 0
    internal_rate_hz: 24000
    provider_pref:
      input_encoding: pcm16
      input_sample_rate_hz: 24000
      output_encoding: pcm16
      output_sample_rate_hz: 24000
    transport_out:
      encoding: slin
      sample_rate_hz: 8000
  telephony_responsive:
    chunk_ms: auto
    idle_cutoff_ms: 600
    internal_rate_hz: 8000
    provider_pref:
      input_encoding: mulaw
      input_sample_rate_hz: 8000
      output_encoding: mulaw
      output_sample_rate_hz: 8000
    transport_out:
      encoding: slin
      sample_rate_hz: 8000
  telephony_ulaw_8k:
    chunk_ms: auto
    idle_cutoff_ms: 800
    internal_rate_hz: 8000
    provider_pref:
      input_encoding: mulaw
      input_sample_rate_hz: 8000
      output_encoding: mulaw
      output_sample_rate_hz: 8000
    transport_out:
      encoding: ulaw
      sample_rate_hz: 8000
  wideband_pcm_16k:
    chunk_ms: auto
    idle_cutoff_ms: 1200
    internal_rate_hz: 16000
    provider_pref:
      input_encoding: linear16
      input_sample_rate_hz: 16000
      output_encoding: linear16
      output_sample_rate_hz: 16000
    transport_out:
      encoding: slin16
      sample_rate_hz: 16000
providers:
  deepgram:
    capabilities:
      - stt
      - llm
      - tts
    continuous_input: true
    enabled: true
    greeting: Hello, how can I help you today?
    input_encoding: mulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    instructions: Voice assistant. Answer in 5-8 words. Be direct. Expand only if asked.
    model: nova-2
    output_encoding: mulaw
    output_sample_rate_hz: 8000
    tts_model: aura-2-thalia-en
    type: full
  google_live:
    api_key: ${GOOGLE_API_KEY}
    capabilities:
      - stt
      - llm
      - tts
    continuous_input: true
    enable_input_transcription: true
    enable_output_transcription: true
    enabled: true
    greeting: >-
      ${GOOGLE_LIVE_GREETING:-Hi! I'm powered by Google Gemini Live API. Try
      interrupting me!}
    input_encoding: ulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    llm_max_output_tokens: 8192
    llm_model: gemini-2.5-flash-native-audio-preview-12-2025
    llm_temperature: 0.8
    llm_top_k: 40
    llm_top_p: 0.95
    output_encoding: linear16
    output_sample_rate_hz: 24000
    provider_input_encoding: linear16
    provider_input_sample_rate_hz: 16000
    response_modalities: audio
    target_encoding: ulaw
    target_sample_rate_hz: 8000
    tts_voice_name: Aoede
    type: full
  local:
    # Local AI Server WebSocket URL. Default deployment uses host networking, so 127.0.0.1 is correct.
    # If you run containers on a user-defined bridge network (no host networking), use ws://local_ai_server:8765.
    base_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
    auth_token: ${LOCAL_WS_AUTH_TOKEN:-}
    capabilities:
      - stt
      - llm
      - tts
    chunk_ms: ${LOCAL_WS_CHUNK_MS:=320}
    connect_timeout_sec: ${LOCAL_WS_CONNECT_TIMEOUT:=2.0}
    continuous_input: true
    enabled: true
    farewell_mode: ${LOCAL_FAREWELL_MODE:=asterisk}
    farewell_timeout_sec: ${LOCAL_FAREWELL_TIMEOUT:=30.0}
    greeting: Hello! I'm your local AI assistant running entirely on-premises.
    instructions: >-
      You are a helpful voice assistant running locally. Be concise and
      friendly.
    llm_model: models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf
    max_tokens: 64
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    stt_model: models/stt/vosk-model-en-us-0.22
    temperature: 0.4
    tts_voice: models/tts/en_US-lessac-medium.onnx
    type: full
  local_llm:
    auth_token: ${LOCAL_WS_AUTH_TOKEN:-}
    capabilities:
      - llm
    enabled: true
    llm_model: models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf
    max_tokens: 32
    temperature: 0.4
    type: local
    # Uses LOCAL_WS_URL (see providers.local.base_url note above).
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  local_stt:
    auth_token: ${LOCAL_WS_AUTH_TOKEN:-}
    capabilities:
      - stt
    chunk_ms: ${LOCAL_WS_CHUNK_MS:=320}
    connect_timeout_sec: ${LOCAL_WS_CONNECT_TIMEOUT:=2.0}
    enabled: true
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    stt_backend: vosk
    stt_model: models/stt/vosk-model-en-us-0.22
    type: local
    # Uses LOCAL_WS_URL (see providers.local.base_url note above).
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  local_tts:
    auth_token: ${LOCAL_WS_AUTH_TOKEN:-}
    capabilities:
      - tts
    enabled: true
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    tts_voice: models/tts/en_US-lessac-medium.onnx
    type: local
    # Uses LOCAL_WS_URL (see providers.local.base_url note above).
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  openai_llm:
    capabilities:
      - llm
    api_key: ${OPENAI_API_KEY}
    chat_base_url: https://api.openai.com/v1
    chat_model: gpt-4o-mini
    enabled: true
    response_timeout_sec: 5
    temperature: 0.7
    type: openai
  groq_llm:
    capabilities:
      - llm
    api_key: ${GROQ_API_KEY}
    chat_base_url: https://api.groq.com/openai/v1
    chat_model: llama-3.3-70b-versatile
    enabled: true
    response_timeout_sec: 10
    temperature: 0.7
    tools_enabled: false
    type: openai
  groq_stt:
    capabilities:
      - stt
    type: groq
    enabled: false
    # API key comes from GROQ_API_KEY env var
    stt_base_url: https://api.groq.com/openai/v1/audio/transcriptions
    stt_model: whisper-large-v3-turbo
    response_format: json
    temperature: 0
    request_timeout_sec: 15
  groq_tts:
    capabilities:
      - tts
    type: groq
    enabled: false
    # API key comes from GROQ_API_KEY env var
    tts_base_url: https://api.groq.com/openai/v1/audio/speech
    tts_model: canopylabs/orpheus-v1-english
    voice: hannah
    response_format: wav
    max_input_chars: 200
    target_encoding: mulaw
    target_sample_rate_hz: 8000
    chunk_size_ms: 20
    request_timeout_sec: 15
  ollama_llm:
    capabilities:
      - llm
    base_url: http://localhost:11434
    model: llama3.2
    enabled: false
    temperature: 0.7
    max_tokens: 200
    timeout_sec: 60
    tools_enabled: true
    type: ollama
  openai_realtime:
    base_url: wss://api.openai.com/v1/realtime
    capabilities:
      - stt
      - llm
      - tts
    continuous_input: true
    egress_pacer_enabled: false
    egress_pacer_warmup_ms: 320
    enabled: true
    greeting: Hello, how can I help you today?
    input_encoding: ulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    instructions: You are a voice assistant. Always speak your responses out loud.
    max_response_output_tokens: 4096
    api_version: beta
    model: gpt-4o-realtime-preview-2024-12-17
    organization: ''
    output_encoding: mulaw
    output_sample_rate_hz: 24000
    provider_input_encoding: linear16
    provider_input_sample_rate_hz: 24000
    response_modalities:
      - audio
      - text
    target_encoding: mulaw
    target_sample_rate_hz: 8000
    temperature: 0.6
    turn_detection:
      create_response: true
      prefix_padding_ms: 300
      silence_duration_ms: 1000
      threshold: 0.5
      type: server_vad
    type: openai_realtime
    voice: alloy
  elevenlabs_agent:
    type: full
    enabled: true
    capabilities:
      - stt
      - llm
      - tts
    input_encoding: ulaw
    input_sample_rate_hz: 8000
    provider_input_encoding: pcm16
    provider_input_sample_rate_hz: 16000
    output_encoding: pcm16
    output_sample_rate_hz: 16000
    target_encoding: ulaw
    target_sample_rate_hz: 8000
    voice_id: uDsPstFWFBUXjIBimV7s
    model_id: eleven_flash_v2_5
    voice_settings:
      stability: 0.5
      similarity_boost: 0.75
      style: 0
      use_speaker_boost: true
    greeting: Hello! I'm your ElevenLabs voice assistant. How can I help you today?
    instructions: You are a helpful voice assistant. Be concise and friendly.
    continuous_input: true
    input_gain_target_rms: 0
    input_gain_max_db: 0
  openai_stt:
    enabled: true
    capabilities:
      - stt
    input_encoding: linear16
    input_sample_rate_hz: 16000
    stt_base_url: https://api.openai.com/v1/audio/transcriptions
    stt_model: whisper-1
    response_format: json
    temperature: 0
    request_timeout_sec: 15
    type: openai
  openai_tts:
    enabled: true
    capabilities:
      - tts
    response_format: wav
    target_encoding: mulaw
    target_sample_rate_hz: 8000
    tts_base_url: https://api.openai.com/v1/audio/speech
    tts_model: tts-1
    type: openai
    voice: alloy
streaming:
  chunk_size_ms: 20
  connection_timeout_ms: 120000
  continuous_stream: true
  diag_enable_taps: true
  diag_out_dir: /tmp/ai-engine-taps
  diag_post_secs: 1
  diag_pre_secs: 1
  empty_backoff_ticks_max: 5
  fallback_timeout_ms: 8000
  greeting_min_start_ms: 40
  # ExternalMedia greeting reliability: wait briefly for inbound RTP to establish the remote endpoint,
  # then fall back to file playback if RTP is still not routable (Asterisk may not emit RTP until speech).
  greeting_rtp_wait_ms: 250
  jitter_buffer_ms: 950
  keepalive_interval_ms: 5000
  low_watermark_ms: 80
  min_start_ms: 120
  normalizer:
    enabled: true
    max_gain_db: 18
    target_rms: 1400
  provider_grace_ms: 200
  sample_rate: 8000

# ============================================================================
# In-Call HTTP Tools (AI-invokable during conversation)
# ============================================================================
in_call_tools:
  # Example: n8n intent router (in-call) - AI sends the user message to an n8n webhook
  # Disabled by default. Enable and set URL to test.
  sample_n8n_in_call_tool:
    kind: in_call_http_lookup
    enabled: false
    is_global: false
    description: "Example in-call tool: send user message to an n8n webhook and return a reply."
    timeout_ms: 5000
    url: "https://your-n8n-instance.com/webhook/intent-router"
    method: POST
    headers:
      Content-Type: "application/json"
      # Authorization: "Bearer ${N8N_API_KEY}"
    body_template: |
      {
        "call_id": "{call_id}",
        "caller_number": "{caller_number}",
        "context": "{context_name}",
        "userMessage": "{userMessage}"
      }
    parameters:
      - name: userMessage
        type: string
        description: "The user message to send to the webhook."
        required: true
    output_variables:
      reply: "reply"
      intent: "intent"
    return_raw_json: false
    error_message: "I couldn't reach the automation service right now. Please try again."
tools:
  ai_identity:
    name: AI Agent
    number: '6789'
  
  # ============================================================================
  # Phase Tools (Milestone 24) - Pre-call and Post-call HTTP integrations
  # ============================================================================

  # Example: GoHighLevel pre-call lookup (context-specific)
  # Disabled by default. Enable and set URL/headers for your GHL account to test.
  sample_gohighlevel_pre_call_lookup:
    kind: generic_http_lookup
    phase: pre_call
    enabled: false
    is_global: false
    timeout_ms: 5000
    hold_audio_file: "custom/please-wait"
    hold_audio_threshold_ms: 500
    url: "https://services.leadconnectorhq.com/contacts/search"
    method: POST
    headers:
      Content-Type: "application/json"
      # Authorization: "Bearer ${GHL_API_KEY}"
      # Version: "2021-07-28"
    body_template: |
      {
        "query": "{caller_number}"
      }
    output_variables:
      ghl_contact_id: "contacts[0].id"
      ghl_contact_name: "contacts[0].name"
      ghl_contact_email: "contacts[0].email"
  
  # Example: Post-call webhook (global - fires for all calls)
  # Sends call data to external system after call ends
  demo_post_call_webhook:
    kind: generic_webhook
    phase: post_call
    enabled: false  # Set to true and configure URL to test
    is_global: true
    timeout_ms: 5000
    url: "https://your-webhook-endpoint.com/call-completed"
    method: POST
    headers:
      Content-Type: "application/json"
      # Authorization: "Bearer ${WEBHOOK_API_KEY}"
    payload_template: |
      {
        "schema_version": 1,
        "event_type": "call_completed",
        "call_id": "{call_id}",
        "caller_number": "{caller_number}",
        "caller_name": "{caller_name}",
        "call_duration": {call_duration},
        "call_outcome": "{call_outcome}",
        "transcript": {transcript_json},
        "context": "{context_name}",
        "provider": "{provider}",
        "timestamp": "{call_end_time}"
      }

  # Example: Discord webhook - posts call summary to a Discord channel (context-specific)
  # Disabled by default. Enable and add your Discord webhook URL to test.
  sample_discord_post_call_webhook:
    kind: generic_webhook
    phase: post_call
    enabled: false
    is_global: false
    timeout_ms: 5000
    url: "https://discord.com/api/webhooks/YOUR_WEBHOOK_ID/YOUR_WEBHOOK_TOKEN"
    method: POST
    headers:
      Content-Type: "application/json"
    payload_template: |
      {
        "content": "Call completed\\nContext: {context_name}\\nCaller: {caller_number} ({caller_name})\\nDuration: {call_duration}s\\nOutcome: {call_outcome}\\nProvider: {provider}\\n\\nSummary: {summary}"
      }
    generate_summary: true

  # Example: Discord webhook - posts call summary to a Discord channel
  # discord_webhook:
  #   kind: generic_webhook
  #   phase: post_call
  #   enabled: false  # Set to true and add your webhook URL
  #   is_global: true
  #   timeout_ms: 5000
  #   url: "https://discord.com/api/webhooks/YOUR_WEBHOOK_ID/YOUR_WEBHOOK_TOKEN"
  #   method: POST
  #   headers:
  #     Content-Type: "application/json"
  #   payload_template: |
  #     {"content": "📞 **Call Completed**\n\n**Duration:** {call_duration}s\n**Outcome:** {call_outcome}\n**Context:** {context_name}\n**Provider:** {provider}\n**Time:** {call_end_time}\n\n**Summary:**\n{summary}"}
  #   generate_summary: true

  # Example: n8n workflow webhook - triggers n8n automation after calls
  # n8n_webhook:
  #   kind: generic_webhook
  #   phase: post_call
  #   enabled: false  # Set to true and add your n8n webhook URL
  #   is_global: true
  #   timeout_ms: 5000
  #   url: "https://your-n8n-instance.com/webhook/your-webhook-path"
  #   method: POST
  #   headers:
  #     Content-Type: "application/json"
  #   payload_template: |
  #     {
  #       "event_type": "call_completed",
  #       "call_id": "{call_id}",
  #       "caller_number": "{caller_number}",
  #       "caller_name": "{caller_name}",
  #       "call_duration": {call_duration},
  #       "call_outcome": "{call_outcome}",
  #       "summary": "{summary}",
  #       "context": "{context_name}",
  #       "provider": "{provider}",
  #       "timestamp": "{call_end_time}"
  #     }
  #   generate_summary: true

  # Example: Pre-call CRM lookup (context-specific)
  # Fetches customer data before AI speaks
  # demo_crm_lookup:
  #   kind: generic_http_lookup
  #   phase: pre_call
  #   enabled: false
  #   is_global: false
  #   timeout_ms: 2000
  #   hold_audio_file: "custom/please-wait"  # Asterisk sound file
  #   hold_audio_threshold_ms: 500
  #   url: "https://api.example.com/contacts/lookup"
  #   method: GET
  #   headers:
  #     Authorization: "Bearer ${CRM_API_KEY}"
  #   query_params:
  #     phone: "{caller_number}"
  #   output_variables:
  #     customer_name: "contact.name"
  #     customer_email: "contact.email"
  #     account_status: "contact.status"
  cancel_transfer:
    allow_after_answer: false
    allow_during_ring: true
    enabled: true
  default_action_timeout: 30
  enabled: true
  extensions:
    internal:
      '6000':
        action_type: transfer
        aliases:
          - agent
          - representative
          - human
          - real person
          - live person
          - someone
          - support
          - sales
          - operator
          - help desk
        description: Live customer service representative
        dial_string: SIP/6000
        mode: warm
        name: Live Agent
        pass_caller_info: true
        timeout: 30
        transfer: true
  hangup_call:
    enabled: true
    farewell_message: Thank you for calling. Goodbye!
    require_confirmation: false
    policy:
      mode: normal
      enforce_transcript_offer: true
      block_during_contact_capture: true
      markers:
        end_call:
          - no transcript
          - no transcript needed
          - don't send a transcript
          - do not send a transcript
          - no need for a transcript
          - no thanks
          - no thank you
          - that's all
          - that is all
          - that's it
          - that is it
          - nothing else
          - all set
          - all good
          - end the call
          - end call
          - hang up
          - hangup
          - goodbye
          - bye
        assistant_farewell:
          - goodbye
          - bye
          - thank you for calling
          - thanks for calling
          - have a great day
          - have a good day
          - take care
          - ending the call
          - i'll let you go
        affirmative:
          - yes
          - yeah
          - yep
          - correct
          - that's correct
          - thats correct
          - that's right
          - thats right
          - right
          - exactly
          - affirmative
        negative:
          - no
          - nope
          - nah
          - negative
          - don't
          - dont
          - do not
          - not
          - not needed
          - no need
          - no thanks
          - no thank you
          - decline
          - skip
  leave_voicemail:
    enabled: true
    extension: '2765'
  request_transcript:
    admin_email: admin@yourdomain.com
    api_key: ${RESEND_API_KEY}
    common_domains:
      - gmail.com
      - yahoo.com
      - outlook.com
      - hotmail.com
      - icloud.com
    confirm_email: true
    enabled: false
    from_email: agent@yourdomain.com
    from_name: AI Voice Agent
    max_attempts: 2
    provider: resend
    validate_domain: true
  send_email_summary:
    admin_email: admin@yourdomain.com
    api_key: ${RESEND_API_KEY}
    enabled: false
    from_email: agent@yourdomain.com
    from_name: AI Voice Agent
    include_metadata: true
    include_transcript: true
    provider: resend
  transfer:
    technology: SIP
    destinations:
      sales_agent:
        description: Sales agent
        target: '2765'
        type: extension
      sales_queue:
        description: Sales team queue
        target: '300'
        type: queue
      sales_team:
        description: Sales team ring group
        target: '600'
        type: ringgroup
      support_agent:
        description: Support agent
        target: '6000'
        type: extension
      support_queue:
        description: Technical support queue
        target: '301'
        type: queue
      support_team:
        description: Support team ring group
        target: '601'
        type: ringgroup
    enabled: true
mcp:
  enabled: true
  servers:
    weather:
      transport: stdio
      command:
        - python3
        - '-m'
        - src.mcp_servers.weather_mcp_server
      defaults:
        timeout_ms: 15000
        slow_response_threshold_ms: 3000
        slow_response_message: Let me check the weather for you, one moment...
      tools:
        - name: get_weather_by_city
          expose_as: mcp_weather_get_city
          speech_field: spoken
    aviation_atis:
      transport: stdio
      command:
        - python3
        - '-m'
        - src.mcp_servers.aviation_atis_server
        - '--config'
        - /app/config/aviation_atis.yaml
      env:
        METNO_USER_AGENT: >-
          Asterisk-AI-Voice-Agent
          (+https://github.com/hkjarral/Asterisk-AI-Voice-Agent)
      defaults:
        timeout_ms: 15000
        slow_response_threshold_ms: 3000
        slow_response_message: Let me get the current ATIS for you, one moment...
      tools:
        - name: get_atis
          expose_as: mcp_aviation_atis
          description: Get current ATIS for an ICAO airport code (e.g., LSMP, KJFK)
          speech_field: atis_text
vad:
  enhanced_enabled: true
  fallback_buffer_size: 128000
  fallback_enabled: true
  fallback_interval_ms: 4000
  max_utterance_duration_ms: 10000
  min_utterance_duration_ms: 600
  use_provider_vad: false
  utterance_padding_ms: 200
  webrtc_aggressiveness: 1
  webrtc_end_silence_frames: 50
  webrtc_start_frames: 3
