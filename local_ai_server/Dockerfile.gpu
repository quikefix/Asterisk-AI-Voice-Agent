# --- Stage 1: Builder (CUDA-enabled dependencies) ---
FROM nvidia/cuda:12.4.1-devel-ubuntu22.04 as builder

# Build args - keep parity with Dockerfile where possible
ARG INCLUDE_VOSK=true
ARG INCLUDE_SHERPA=true
ARG INCLUDE_FASTER_WHISPER=false
ARG INCLUDE_WHISPER_CPP=false
ARG INCLUDE_PIPER=true
ARG INCLUDE_KOKORO=true
ARG INCLUDE_MELOTTS=false
ARG INCLUDE_LLAMA=true
ARG MELOTTS_GIT_REF=b633f243412169b999526e19eb6fcac0974b5d30

ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get -o Acquire::Retries=5 update && \
    apt-get install -y --no-install-recommends \
        python3 \
        python3-venv \
        python3-pip \
        build-essential \
        cmake \
        git \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /usr/src/app

# Create virtual environment
RUN python3 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
ENV NLTK_DATA="/opt/venv/nltk_data"
ENV CUDA_HOME=/usr/local/cuda
ENV LIBRARY_PATH="${CUDA_HOME}/lib64/stubs:${LIBRARY_PATH}"
ENV LD_LIBRARY_PATH="${CUDA_HOME}/lib64/stubs:${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}"

# Make libcuda SONAME discoverable during build-time linking in containers.
RUN if [ -f "${CUDA_HOME}/lib64/stubs/libcuda.so" ] && [ ! -e "${CUDA_HOME}/lib64/stubs/libcuda.so.1" ]; then \
        ln -s "${CUDA_HOME}/lib64/stubs/libcuda.so" "${CUDA_HOME}/lib64/stubs/libcuda.so.1"; \
    fi

# Copy requirements first for optimal caching
COPY requirements-base.txt .

# Install base dependencies (always required)
RUN pip install --no-cache-dir --upgrade pip setuptools wheel && \
    pip install --no-cache-dir -r requirements-base.txt

# Conditionally install backends based on build args
RUN if [ "$INCLUDE_VOSK" = "true" ]; then \
        pip install --no-cache-dir vosk==0.3.45; \
    fi

RUN if [ "$INCLUDE_SHERPA" = "true" ]; then \
        pip install --no-cache-dir sherpa-onnx==1.12.19; \
    fi

RUN if [ "$INCLUDE_FASTER_WHISPER" = "true" ]; then \
        pip install --no-cache-dir faster-whisper==1.0.3; \
    fi

RUN if [ "$INCLUDE_WHISPER_CPP" = "true" ]; then \
        pip install --no-cache-dir pywhispercpp==1.2.0; \
    fi

RUN if [ "$INCLUDE_PIPER" = "true" ]; then \
        pip install --no-cache-dir piper-tts==1.2.0; \
    fi

RUN if [ "$INCLUDE_KOKORO" = "true" ]; then \
        pip install --no-cache-dir "kokoro>=0.9.2"; \
    fi

RUN if [ "$INCLUDE_MELOTTS" = "true" ]; then \
        pip install --no-cache-dir "git+https://github.com/myshell-ai/MeloTTS.git@${MELOTTS_GIT_REF}" && \
        python -m unidic download && \
        python -c "import nltk; nltk.download('averaged_perceptron_tagger_eng', download_dir='/opt/venv/nltk_data')" && \
        python -c "from transformers import AutoTokenizer; AutoTokenizer.from_pretrained('bert-base-uncased')" && \
        python -c "from melo.api import TTS; tts = TTS(language='EN', device='cpu'); print('MeloTTS ready')"; \
    fi

RUN if [ "$INCLUDE_LLAMA" = "true" ]; then \
        CMAKE_ARGS="-DGGML_CUDA=on -DLLAMA_BUILD_TESTS=OFF -DLLAMA_BUILD_EXAMPLES=OFF -DLLAMA_BUILD_TOOLS=OFF" \
        FORCE_CMAKE=1 \
        pip install --no-cache-dir llama-cpp-python==0.3.16; \
    fi

# Pre-install spacy model for Kokoro TTS (only if Kokoro included)
RUN if [ "$INCLUDE_KOKORO" = "true" ]; then \
        python -m spacy download en_core_web_sm; \
    fi

# --- Stage 2: Final Runtime Image (CUDA runtime) ---
FROM nvidia/cuda:12.4.1-runtime-ubuntu22.04

# Build argument to optionally include Kroko embedded server
ARG INCLUDE_KROKO_EMBEDDED=false

ENV DEBIAN_FRONTEND=noninteractive

# Install runtime dependencies
RUN apt-get -o Acquire::Retries=5 update && apt-get install -y --no-install-recommends \
    python3 \
    python3-venv \
    tzdata \
    libsndfile1 \
    libasound2 \
    libportaudio2 \
    libgomp1 \
    libatomic1 \
    sox \
    wget \
    espeak-ng \
    && rm -rf /var/lib/apt/lists/*

# Optional: Install Kroko ONNX server for embedded mode
ARG ONNX_RUNTIME_SHA256="89b153af88746665909c758a06797175ae366280cbf25502c41eb5955f9a555e"
ARG KROKO_SERVER_SHA256=""

RUN if [ "$INCLUDE_KROKO_EMBEDDED" = "true" ]; then \
        wget -q https://github.com/microsoft/onnxruntime/releases/download/v1.17.1/onnxruntime-linux-x64-1.17.1.tgz \
            -O /tmp/onnxruntime.tgz && \
        ACTUAL_ONNX_SHA=$(sha256sum /tmp/onnxruntime.tgz | cut -d' ' -f1) && \
        if [ -n "$ONNX_RUNTIME_SHA256" ] && [ "$ACTUAL_ONNX_SHA" != "$ONNX_RUNTIME_SHA256" ]; then \
            echo "ONNX Runtime checksum mismatch. Build aborted." && \
            exit 1; \
        fi && \
        tar -xzf /tmp/onnxruntime.tgz -C /tmp && \
        mv /tmp/onnxruntime-linux-x64-1.17.1/lib/* /usr/lib/ && \
        rm -rf /tmp/onnxruntime* && \
        if [ -z "$KROKO_SERVER_SHA256" ]; then \
            echo "KROKO_SERVER_SHA256 must be set when INCLUDE_KROKO_EMBEDDED=true. Build aborted." && \
            exit 1; \
        fi && \
        wget -q https://download.kroko.ai/binaries/kroko-onnx-online-websocket-server \
            -O /usr/local/bin/kroko-server && \
        ACTUAL_KROKO_SHA=$(sha256sum /usr/local/bin/kroko-server | cut -d' ' -f1) && \
        if [ -n "$KROKO_SERVER_SHA256" ] && [ "$ACTUAL_KROKO_SHA" != "$KROKO_SERVER_SHA256" ]; then \
            echo "Kroko checksum mismatch. Build aborted." && \
            exit 1; \
        fi && \
        chmod +x /usr/local/bin/kroko-server; \
    fi

WORKDIR /app

# Create non-root user for security
RUN useradd --create-home appuser
USER appuser

# Copy the virtual environment from builder
COPY --from=builder /opt/venv /opt/venv

# Copy application source code
COPY --chown=appuser:appuser . .

# Set PATH for virtual environment
ENV PATH="/opt/venv/bin:$PATH"
ENV NLTK_DATA="/opt/venv/nltk_data"

# Run the application
CMD ["python", "main.py"]
